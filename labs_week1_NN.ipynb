{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOFTdjj5U0q93yHuQ7MF71U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fawzy-AI-Explorer/-Gold-Price-Prediction./blob/main/labs_week1_NN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lab1"
      ],
      "metadata": {
        "id": "mMxX567_cILg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "_yU8n_paBts2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.losses import MeanSquaredError, BinaryCrossentropy\n",
        "from tensorflow.keras.activations import sigmoid\n",
        "import logging\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
        "tf.autograph.set_verbosity(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.array([[ 1 , 2 , 3 ],\n",
        "                    [ 2 , 1 , 3 ]]\n",
        "                   , dtype=np.float32)\n",
        "\n",
        "\n",
        "Y_train = np.array([[300.0],\n",
        "                    [500.0]],\n",
        "                    dtype=np.float32)\n"
      ],
      "metadata": {
        "id": "OmiWHK9XBzLJ"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = X_train[0].reshape(-1,1)\n",
        "x_train  #3*1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyYIYBXGuQnI",
        "outputId": "7a932475-87a4-4f52-8371-821b8ff06884"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.],\n",
              "       [2.],\n",
              "       [3.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_layer = tf.keras.layers.Dense(units=1, activation = 'linear', )\n",
        "linear_layer(x_train)\n",
        "linear_layer.get_weights() #1*1 ,b= 1*1"
      ],
      "metadata": {
        "id": "r6Bk7z2YuEB8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1058f3f9-3dd6-4dd3-b54f-e7c397ce777b"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-1.1355891]], dtype=float32), array([0.], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_layer = tf.keras.layers.Dense(units=1, activation = 'linear', )\n",
        "linear_layer(X_train)\n",
        "linear_layer.get_weights()  #3*1, b=1*1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nD_6eL40uKO0",
        "outputId": "c70324df-dedd-4c54-8acb-32ea375da790"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[-1.1083611 ],\n",
              "        [-0.13257182],\n",
              "        [ 0.8758961 ]], dtype=float32),\n",
              " array([0.], dtype=float32)]"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#each training example in a row\n",
        "'''\n",
        "[1]\n",
        "[3]\n",
        "[4]\n",
        "3 tr ex. 1 feat\n",
        "\n",
        "[1,2]\n",
        "[3,7]\n",
        "[4,9]\n",
        "3 tr ex. 2 feat\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "yrVltoFaXLId",
        "outputId": "3f30156e-0f09-4c2c-984f-5eff8555d6a1"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n[1]\\n[3]\\n[4]\\n3 tr ex. 1 feat\\n\\n[1,2]\\n[3,7]\\n[4,9]\\n3 tr ex. 2 feat\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4uNVSVHWXLFG"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a3nezx0yXLCp"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sw = np.array([ [4],\n",
        "                [5],\n",
        "                [1] ])\n",
        "sb =np.array( [0] )\n",
        "linear_layer.set_weights([sw,sb])\n",
        "linear_layer(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiufsOE0ukwt",
        "outputId": "bdcd2d75-710d-43c5-bd6b-0c8bdbcc28e3"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
              "array([[17.],\n",
              "       [16.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alin = np.dot ( X_train , sw ) + sb\n",
        "             # 2*3    3*1     1*1\n",
        "             #    2*1\n",
        "alin\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfkkXedjwbio",
        "outputId": "8f784fca-b54c-411f-c30d-1e47e741e702"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[17.],\n",
              "       [16.]])"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Dense(1,  input_dim=3 , activation = 'sigmoid', name='L1')\n",
        "    ]\n",
        ")\n",
        "\n",
        "model(X_train)  # 2*3\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "uN4oZUXs1cfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a04b786-910b-4067-b896-1b7e36c39688"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " L1 (Dense)                  (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4 (16.00 Byte)\n",
            "Trainable params: 4 (16.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J_goqc7F6g3o"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "imnT0eMM6XFt"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.dot (X_train , sw) +sb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9U6OSS3d7LVE",
        "outputId": "b526dd10-0443-491b-f1cc-0b4536d46059"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[17.],\n",
              "       [16.]])"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model(X_train)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3CdTlzs6Y6R",
        "outputId": "6ba19537-c52a-40b6-acc6-c082043be506"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
              "array([[0.98572963],\n",
              "       [0.9882335 ]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "arh2tQcQ6tFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lab2\n"
      ],
      "metadata": {
        "id": "2u_8f9rL739j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(f\"Temperature Max, Min pre normalization: {np.max(X[:,0]):0.2f}, {np.min(X[:,0]):0.2f}\")\n",
        "# print(f\"Duration    Max, Min pre normalization: {np.max(X[:,1]):0.2f}, {np.min(X[:,1]):0.2f}\")\n",
        "\n",
        "\n",
        "# norm_l = tf.keras.layers.Normalization(axis=-1) #**************************************************************************************\n",
        "# norm_l.adapt(X)  # learns mean, variance\n",
        "# Xn = norm_l(X)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(f\"Temperature Max, Min post normalization: {np.max(Xn[:,0]):0.2f}, {np.min(Xn[:,0]):0.2f}\")\n",
        "# print(f\"Duration    Max, Min post normalization: {np.max(Xn[:,1]):0.2f}, {np.min(Xn[:,1]):0.2f}\")"
      ],
      "metadata": {
        "id": "YAiRYD5SDs9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.random.set_seed(1234)  # applied to achieve consistent results\n",
        "model = Sequential(\n",
        "    [\n",
        "        tf.keras.Input(shape=(2,)), #specifies the expected shape of the input This allows Tensorflow to size the weights and bias parameters at this point.\n",
        "        Dense(3, activation='sigmoid', name = 'layer1'),\n",
        "        Dense(1, activation='sigmoid', name = 'layer2')\n",
        "     ]\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpL-dP7q75yb",
        "outputId": "ecec9cc0-8d77-4a66-d41f-edce7c357aea"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " layer1 (Dense)              (None, 3)                 9         \n",
            "                                                                 \n",
            " layer2 (Dense)              (None, 1)                 4         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13 (52.00 Byte)\n",
            "Trainable params: 13 (52.00 Byte)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "L1_num_params = 2 * 3 + 3   # W1 parameters  + b1 parameters\n",
        "L2_num_params = 3 * 1 + 1   # W2 parameters  + b2 parameters\n",
        "print(\"L1 params = \", L1_num_params, \", L2 params = \", L2_num_params  )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9yCBaUC_lql",
        "outputId": "bca3bf7c-a825-463b-bcc3-9b782edec879"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1 params =  9 , L2 params =  4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "W1, b1 = model.get_layer(\"layer1\").get_weights()\n",
        "W2, b2 = model.get_layer(\"layer2\").get_weights()\n",
        "print(f\"W1{W1.shape}:\\n\", W1, f\"\\nb1{b1.shape}:\", b1)\n",
        "print(f\"W2{W2.shape}:\\n\", W2, f\"\\nb2{b2.shape}:\", b2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K6EhqVT_pCf",
        "outputId": "960f48b4-2a14-4a4f-9f22-514667deeab3"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "W1(2, 3):\n",
            " [[ 0.6562191   0.9882722  -0.38974804]\n",
            " [-0.32380646  0.09636497 -0.5891686 ]] \n",
            "b1(3,): [0. 0. 0.]\n",
            "W2(3, 1):\n",
            " [[-1.049754 ]\n",
            " [-1.0710602]\n",
            " [-1.0590913]] \n",
            "b2(1,): [0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model.compile(                    #statement defines a loss function and specifies a compile optimization.\n",
        "#     loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "#     optimizer = tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "# )\n",
        "\n",
        "# model.fit(                   #statement runs gradient descent and fits the weights to the data\n",
        "#     Xt,Yt,\n",
        "#     epochs=10,\n",
        "# )\n"
      ],
      "metadata": {
        "id": "HPg9KuRL_uiB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Epochs and batches\n",
        "In the `fit` statement above, the number of `epochs` was set to 10. This specifies that the entire data set should be applied during training 10 times.  During training, you see output describing the progress of training that looks like this:\n",
        "```\n",
        "Epoch 1/10\n",
        "6250/6250 [==============================] - 6s 910us/step - loss: 0.1782\n",
        "```\n",
        "The first line, `Epoch 1/10`, describes which epoch the model is currently running. For efficiency, the training data set is broken into 'batches'. The default size of a batch in Tensorflow is 32. There are 200000 examples in our expanded data set or 6250 batches ( 200000 / 32 = 6250). The notation on the 2nd line `6250/6250 [====` is describing which batch has been executed."
      ],
      "metadata": {
        "id": "MpIdtyHjAf0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "200000 / 32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dluUbLRE_zgS",
        "outputId": "407966ef-2117-4684-e9e6-4bcc88b69538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6250.0"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once you have a trained model, you can then use it to make predictions. Recall that the output of our model is a probability. In this case, the probability of a good roast. To make a decision, one must apply the probability to a threshold. In this case, we will use 0.5"
      ],
      "metadata": {
        "id": "xsIDVfzhBsRH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.array([\n",
        "    [200,13.9],  # positive example\n",
        "    [200,17]])   # negative example\n",
        "# X_testn = norm_l(X_test)          #normalization\n",
        "# predictions = model.predict(X_testn)\n",
        "predictions = np.array([[9.89e-01] ,[4.94e-08]])\n",
        "print(\"predictions = \\n\", predictions) #probability"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xz0YD9mjAn6W",
        "outputId": "3a5f8c3a-e0fd-4892-b583-3b825a6c9711"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "predictions = \n",
            " [[9.89e-01]\n",
            " [4.94e-08]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "predictions =\n",
        " [[9.89e-01]\n",
        " [4.94e-08]]"
      ],
      "metadata": {
        "id": "eUxkAia8CNd_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# To convert the probabilities to a decision, we apply a threshold:\n",
        "yhat = np.zeros_like(predictions)\n",
        "for i in range(len(predictions)):\n",
        "    if predictions[i] >= 0.5:\n",
        "        yhat[i] = 1\n",
        "    else:\n",
        "        yhat[i] = 0\n",
        "print(f\"decisions = \\n{yhat}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EizXhlBhCN5A",
        "outputId": "6b099856-6be1-4f94-d1e1-3b060066f820"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decisions = \n",
            "[[1.]\n",
            " [0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#the same\n",
        "yhat = (predictions >= 0.5).astype(int)\n",
        "print(f\"decisions = \\n{yhat}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMXzI5ojCXDP",
        "outputId": "57569b34-13cf-471e-dee2-8a1299ee23f0"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "decisions = \n",
            "[[1]\n",
            " [0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lab3"
      ],
      "metadata": {
        "id": "Epe-QPpDIl6j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.zeros(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTFSTcYFCtUT",
        "outputId": "0fe06c7c-865c-4d13-e028-6601ed54a01b"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def g(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "#*****************************************\n",
        "#*****************************************\n",
        "#*****************************************\n",
        "def my_dense(a_in, W, b):\n",
        "    \"\"\"\n",
        "    Computes dense layer\n",
        "    Args:\n",
        "      a_in (ndarray (n, )) : Data, 1 example\n",
        "      W    (ndarray (n,j)) : Weight matrix, n features per unit, j units\n",
        "      b    (ndarray (j, )) : bias vector, j units\n",
        "    Returns\n",
        "      a_out (ndarray (j,))  : j units|\n",
        "    \"\"\"\n",
        "    units = W.shape[1]          # num nodes in the next layer\n",
        "    a_out = np.zeros(units)     # num nodes in the next layer\n",
        "    for j in range(units):\n",
        "        w = W[:,j]\n",
        "        z = np.dot(w, a_in) + b[j]\n",
        "        a_out[j] = g(z)\n",
        "    return(a_out)\n",
        "#*****************************************\n",
        "#*****************************************\n",
        "#*****************************************\n",
        "def my_sequential(x, W1, b1, W2, b2):\n",
        "    a1 = my_dense(x,  W1, b1)\n",
        "    a2 = my_dense(a1, W2, b2)\n",
        "    return(a2)\n",
        "#*****************************************\n",
        "#*****************************************\n",
        "#*****************************************\n",
        "W1_tmp = np.array( [[-8.93,  0.29, 12.9 ],\n",
        "                    [-0.1,  -7.32, 10.81]] )\n",
        "\n",
        "b1_tmp = np.array( [-9.82, -9.28,  0.96] )\n",
        "\n",
        "W2_tmp = np.array( [[-31.18],\n",
        "                    [-27.59],\n",
        "                    [-32.56]] )\n",
        "\n",
        "b2_tmp = np.array( [15.41] )\n",
        "\n",
        "#*****************************************\n",
        "#*****************************************\n",
        "#*****************************************\n",
        "\n",
        "def my_predict(X, W1, b1, W2, b2):\n",
        "    m = X.shape[0]              #num of training examoles\n",
        "    p = np.zeros((m,1))\n",
        "    for i in range(m):\n",
        "        p[i,0] = my_sequential(X[i], W1, b1, W2, b2)\n",
        "    return(p)\n",
        "#*****************************************\n",
        "#*****************************************\n",
        "#*****************************************\n",
        "X_tst = np.array([\n",
        "    [200,13.9],  # postive example\n",
        "    [200,17]])   # negative example\n",
        "\n",
        "\n",
        "norm_l = tf.keras.layers.Normalization(axis=-1)\n",
        "norm_l.adapt(X_tst)  # learns mean, variance\n",
        "X_tst = norm_l(X_tst)\n",
        "\n",
        "\n",
        "predictions = my_predict(X_tst, W1_tmp, b1_tmp, W2_tmp, b2_tmp)\n",
        "predictions #probabilites\n",
        "\n",
        "\n",
        "#*****************************************\n",
        "#*****************************************\n",
        "#*****************************************\n",
        "\n",
        "# yhat = np.zeros_like(predictions)\n",
        "# for i in range(len(predictions)):\n",
        "#     if predictions[i] >= 0.5:\n",
        "#         yhat[i] = 1\n",
        "#     else:\n",
        "#         yhat[i] = 0\n",
        "# print(f\"decisions = \\n{yhat}\")\n",
        "\n",
        "# the same\n",
        "yhat = (predictions >= 0.5).astype(int)\n",
        "yhat"
      ],
      "metadata": {
        "id": "tgYH49KmEhpS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0022d8a-1c5f-4222-b3b9-dd4c13449a25"
      },
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-178-47946687cf74>:52: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  p[i,0] = my_sequential(X[i], W1, b1, W2, b2)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gCJC_SGH56t",
        "outputId": "31057300-ee83-4174-ab2e-3dda417d1e49"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# end week1"
      ],
      "metadata": {
        "id": "GAQqtH0tcMFl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data set contains 1000 training examples of handwritten digits  1\n",
        " , here limited to zero and one. <br>\n",
        "\n",
        "Each training example is a 20-pixel x 20-pixel grayscale image of the digit.\n",
        "Each pixel is represented by a floating-point number indicating the grayscale intensity at that location.<br>\n",
        "The 20 by 20 grid of pixels is “unrolled” into a 400-dimensional vector.<br>\n",
        "Each training example becomes a single row in our data matrix X.<br>\n",
        "This gives us a 1000 x 400 matrix X where every row is a training example of a handwritten digit image.<br>\n",
        "\n",
        "\n",
        "The second part of the training set is a 1000 x 1 dimensional vector y that contains labels for the training set<br>\n",
        "y = 0 if the image is of the digit 0, y = 1 if the image is of the digit 1.<br>"
      ],
      "metadata": {
        "id": "K6WdQ1eIgWbR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The parameters have dimensions that are sized for a neural network with  25\n",
        "  units in layer 1,  15 <br>\n",
        "  units in layer 2 and  1 <br>\n",
        "  output unit in layer 3. <br>\n",
        "\n",
        "Recall that the dimensions of these parameters are determined as follows: <br>\n",
        "\n",
        "If network has  𝑠𝑖𝑛\n",
        "  units in a layer and  𝑠𝑜𝑢𝑡\n",
        "  units in the next layer, then\n",
        "𝑊\n",
        "  will be of dimension  𝑠𝑖𝑛×𝑠𝑜𝑢𝑡\n",
        " .\n",
        "𝑏\n",
        "  will a vector with  𝑠𝑜𝑢𝑡\n",
        "  elements\n",
        "Therefore, the shapes of W, and b, are <br>\n",
        "\n",
        "layer1: The shape of W1 is (400, 25) and the shape of b1 is (25,) <br>\n",
        "layer2: The shape of W2 is (25, 15) and the shape of b2 is: (15,) <br>\n",
        "layer3: The shape of W3 is (15, 1) and the shape of b3 is: (1,) <br>\n"
      ],
      "metadata": {
        "id": "p2UXWNu9g6OB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "X, y = load_data()\n",
        "\n",
        "model = Sequential(\n",
        "    [\n",
        "        tf.keras.Input(shape=(400,)),    #specify input size\n",
        "        Dense(25 , activation = \"sigmoid\" , name = \"l1\"),\n",
        "        Dense(15 , activation = \"sigmoid\" , name = \"l2\"),\n",
        "        Dense(1  , activation = \"sigmoid\" , name = \"l3\")\n",
        "      ], name = \"my_model\"\n",
        ")\n",
        "#1000 * 400 , w = [400 * 25] , b=[25] --> op = 1000 * 25\n",
        "# 1000*25   , w = [25* 15] , b=[15]  ---> op = 1000 * 15\n",
        "#1000 * 15  , w = [15 * 1] b=[1] ---->op = 1000 * 1\n",
        "\n",
        "L1_num_params = 400 * 25 + 25  # W1 parameters  + b1 parameters\n",
        "L2_num_params = 25 * 15 + 15   # W2 parameters  + b2 parameters\n",
        "L3_num_params = 15 * 1 + 1     # W3 parameters  + b3 parameters\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "[layer1, layer2, layer3] = model.layers\n",
        "W1,b1 = layer1.get_weights()\n",
        "W2,b2 = layer2.get_weights()\n",
        "W3,b3 = layer3.get_weights()\n",
        "\n",
        "\n",
        "print(model.layers[2].weights) #layer 3\n",
        "\n",
        "#******************************************************************************************************\n",
        "#******************************************************************************************************\n",
        "#******************************************************************************************************\n",
        "#******************************************************************************************************\n",
        "#******************************************************************************************************\n",
        "#******************************************************************************************************\n",
        "# will define a loss function and run gradient descent to fit the weights of the model to the training data.\n",
        "model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
        ")\n",
        "\n",
        "model.fit(\n",
        "    X,y,\n",
        "    epochs=20\n",
        ")\n",
        "#******************************************************************************************************\n",
        "#******************************************************************************************************\n",
        "#******************************************************************************************************\n",
        "#******************************************************************************************************\n",
        "#******************************************************************************************************\n",
        "#******************************************************************************************************\n",
        "#each example in a row (1*400) 400feature , 1 example\n",
        "prediction = model.predict(X[0].reshape(1,400))  # a zero\n",
        "print(f\" predicting a zero: {prediction}\")\n",
        "prediction = model.predict(X[500].reshape(1,400))  # a one\n",
        "print(f\" predicting a one:  {prediction}\")\n",
        "if prediction >= 0.5:\n",
        "    yhat = 1\n",
        "else:\n",
        "    yhat = 0\n",
        "print(f\"prediction after threshold: {yhat}\")\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "_wbQr-jLgRZo",
        "outputId": "4f694413-c5bb-429a-b864-ced02d318528"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nX, y = load_data()\\n\\nmodel = Sequential(\\n    [               \\n        tf.keras.Input(shape=(400,)),    #specify input size\\n        Dense(25 , activation = \"sigmoid\" , name = \"l1\"),\\n        Dense(15 , activation = \"sigmoid\" , name = \"l2\"),\\n        Dense(1  , activation = \"sigmoid\" , name = \"l3\")\\n      ], name = \"my_model\" \\n)                            \\n#1000 * 400 , w = [400 * 25] , b=[25] --> op = 1000 * 25\\n# 1000*25   , w = [25* 15] , b=[15]  ---> op = 1000 * 15\\n#1000 * 15  , w = [15 * 1] b=[1] ---->op = 1000 * 1\\n\\nL1_num_params = 400 * 25 + 25  # W1 parameters  + b1 parameters\\nL2_num_params = 25 * 15 + 15   # W2 parameters  + b2 parameters\\nL3_num_params = 15 * 1 + 1     # W3 parameters  + b3 parameters\\n\\n\\n\\n\\n[layer1, layer2, layer3] = model.layers\\nW1,b1 = layer1.get_weights()\\nW2,b2 = layer2.get_weights()\\nW3,b3 = layer3.get_weights()\\n\\n\\nprint(model.layers[2].weights) #layer 3 \\n\\n#******************************************************************************************************\\n#******************************************************************************************************\\n#******************************************************************************************************\\n#******************************************************************************************************\\n#******************************************************************************************************\\n#******************************************************************************************************\\n# will define a loss function and run gradient descent to fit the weights of the model to the training data.\\nmodel.compile(\\n    loss=tf.keras.losses.BinaryCrossentropy(),\\n    optimizer=tf.keras.optimizers.Adam(0.001),\\n)\\n\\nmodel.fit(\\n    X,y,\\n    epochs=20\\n)\\n#******************************************************************************************************\\n#******************************************************************************************************\\n#******************************************************************************************************\\n#******************************************************************************************************\\n#******************************************************************************************************\\n#******************************************************************************************************\\n#each example in a row (1*400) 400feature , 1 example\\nprediction = model.predict(X[0].reshape(1,400))  # a zero\\nprint(f\" predicting a zero: {prediction}\")\\nprediction = model.predict(X[500].reshape(1,400))  # a one\\nprint(f\" predicting a one:  {prediction}\")\\nif prediction >= 0.5:\\n    yhat = 1\\nelse:\\n    yhat = 0\\nprint(f\"prediction after threshold: {yhat}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_in = np.array([ [1,2,3] ])\n",
        "\n",
        "# W = [1,2,4]\n",
        "W = np.array([ [1,2,3],\n",
        "               [2,4,3],\n",
        "               [7,2,3]])\n",
        "# np.dot(a,w)\n",
        "\n",
        "\n",
        "\n",
        "units = W.shape[1]\n",
        "\n",
        "a_out = np.zeros(units)\n",
        "# print(a_out[0])\n",
        "\n",
        "\n",
        "# a_out[0] = [1]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# print(units , a_out)\n",
        "for i in range (units):\n",
        "    w = W[:,i]\n",
        "    # print(w)\n",
        "    z = np.dot(a_in,w) +1\n",
        "    print(z)\n",
        "    a_out[i] =  z\n",
        "\n",
        "\n",
        "\n",
        "a_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GcjNyz41cNhk",
        "outputId": "c48554a5-68f5-442b-8408-0330bc838299"
      },
      "execution_count": 176,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[27]\n",
            "[17]\n",
            "[19]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-176-0727f15cfd4a>:28: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  a_out[i] =  z\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([27., 17., 19.])"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ipxtagveksgd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def my_dense_v(A_in, W, b, g):\n",
        "    \"\"\"\n",
        "    Computes dense layer\n",
        "    Args:\n",
        "      A_in (ndarray (m,n)) : Data, m examples, n features each\n",
        "      W    (ndarray (n,j)) : Weight matrix, n features per unit, j units\n",
        "      b    (ndarray (1,j)) : bias vector, j units\n",
        "      g    activation function (e.g. sigmoid, relu..)\n",
        "    Returns\n",
        "      A_out (tf.Tensor or ndarray (m,j)) : m examples, j units\n",
        "    \"\"\"\n",
        "    z= np.dot(A_in , W) + b\n",
        "    A_out = g(z)\n",
        "    return(A_out)\n",
        "\n",
        "\n",
        "\n",
        "def my_sequential_v(X, W1, b1, W2, b2, W3, b3):\n",
        "    A1 = my_dense_v(X,  W1, b1, sigmoid)\n",
        "    A2 = my_dense_v(A1, W2, b2, sigmoid)\n",
        "    A3 = my_dense_v(A2, W3, b3, sigmoid)\n",
        "    return(A3)\n",
        "\n",
        "Prediction = my_sequential_v(X, W1_tmp, b1_tmp, W2_tmp, b2_tmp, W3_tmp, b3_tmp )\n",
        "Prediction.shape\n",
        "\n",
        "Yhat = (Prediction >= 0.5).astype(int)\n",
        "print(\"predict a zero: \",Yhat[0], \"predict a one: \", Yhat[500])"
      ],
      "metadata": {
        "id": "jfJNxuqcwNbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DMCZinIDxdgo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tX5ovbI6xddL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([1,2,3]).reshape(-1,1)  #(3,1)\n",
        "b = 5\n",
        "c = a + b\n",
        "# print(f\"(a + b).shape: {(a + b).shape}, \\na + b = \\n{a + b}\")\n",
        "print(f\"a:\\n{a} \\nb:\\n {b}\\nc:\\n{c}\")\n",
        "\n",
        "print(\"*******************************\")\n",
        "\n",
        "w = a*b\n",
        "print(f\"a:\\n{a} \\nb:\\n {b}\\nw:\\n{w}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sgCgwgg1xdal",
        "outputId": "180b1539-1217-4126-ee56-0f42252a856c"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a:\n",
            "[[1]\n",
            " [2]\n",
            " [3]] \n",
            "b:\n",
            " 5\n",
            "c:\n",
            "[[6]\n",
            " [7]\n",
            " [8]]\n",
            "*******************************\n",
            "a:\n",
            "[[1]\n",
            " [2]\n",
            " [3]] \n",
            "b:\n",
            " 5\n",
            "w:\n",
            "[[ 5]\n",
            " [10]\n",
            " [15]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = np.array([1,2,3,4]).reshape(-1,1)\n",
        "b = np.array([1,2,3]).reshape(1,-1)\n",
        "print(a)\n",
        "print(b)\n",
        "print(f\"(a + b).shape: {(a + b).shape}, \\na + b = \\n{a + b}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhYUpCplx_rS",
        "outputId": "ed3f80ba-7aca-4114-f260-6e038253240f"
      },
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1]\n",
            " [2]\n",
            " [3]\n",
            " [4]]\n",
            "[[1 2 3]]\n",
            "(a + b).shape: (4, 3), \n",
            "a + b = \n",
            "[[2 3 4]\n",
            " [3 4 5]\n",
            " [4 5 6]\n",
            " [5 6 7]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_byi8GvoyMZ6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}